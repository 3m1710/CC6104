%\documentclass[mathserif]{beamer}
\documentclass[handout]{beamer}
%\usetheme{Goettingen}
\usetheme{Warsaw}
%\usetheme{Singapore}
%\usetheme{Frankfurt}
%\usetheme{Copenhagen}
%\usetheme{Szeged}
%\usetheme{Montpellier}
%\usetheme{CambridgeUS}
%\usecolortheme{}
%\setbeamercovered{transparent}
\usepackage[english, activeacute]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amssymb}
\usepackage{dsfont}
\usepackage{graphics}
\usepackage{cases}
\usepackage{graphicx}
\usepackage{pgf}
\usepackage{epsfig}
\usepackage{amssymb}
\usepackage{multirow}	
\usepackage{amstext}
\usepackage[ruled,vlined,lined]{algorithm2e}
\usepackage{amsmath}
\usepackage{epic}
\usepackage{epsfig}
\usepackage{fontenc}
\usepackage{framed,color}
\usepackage{palatino, url, multicol}
\usepackage{listings}
%\algsetup{indent=2em}


\vspace{-0.5cm}
\title{Markov Chain Monte Carlo}
\vspace{-0.5cm}
\author[Felipe Bravo Márquez]{\footnotesize
%\author{\footnotesize  
 \textcolor[rgb]{0.00,0.00,1.00}{Felipe José Bravo Márquez}} 
\date{ \today }




\begin{document}
\begin{frame}
\titlepage


\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{frame}{Markov Chain Monte Carlo}
\scriptsize{
\begin{itemize}
\item This class  introduces estimation of posterior probability distributions using a stochastic process known
as \textbf{Markov chain Monte Carlo} (MCMC). 

\item Here we'll produce samples from the joint posterior without maximizing anything. 

\item We will be able to sample directly from the posterior without assuming a Gaussian, or any other, shape. 

\item The cost of this power is that it may take much longer for our estimation to complete.

\item But the benefit is escaping multivariate normality assumption of the Laplace approximation.

\item More advanced models such as the generalized linear and multilevel models tend produce non-Gaussian posterior distributions.

\item In most cases  they cannot
be estimated at all with the techniques of earlier classes. 


\item This class is based on Chapter 9 of \cite{mcelreath2020statistical} and Chapter 7 of \cite{kruschke2014doing}.
 
\end{itemize}



} 

\end{frame}




\begin{frame}{Markov Chain Monte Carlo}
\scriptsize{
\begin{itemize}
\item The essence of MCMC is to produce samples from the posterior $f(\theta|d)$ by only accessing a function that is proportial to it.
\item This proportial function is the product of the likelihood and the prior $f(d|\theta)*f(\theta)$, which is always available in a Bayesian model.
\item So, merely by evaluating $f(d|\theta)*f(\theta)$, without normalizing it by $f(d)$, MCMC allows us to generate random representative values from the posterior distribution.

\item This property is wonderful because the method obviates direct computation of the evidence $f(d)$, which, as you'll recall, is one of the most difficult aspects of Bayesian
inference. 

\item It has only been with the development of MCMC algorithms an software that Bayesian inference is applicable to complex data analysis.
\item And it has only been with the production of fast and cheap computer hardware that Bayesian inference is accessible to a wide audience.

\item The question then becomes this: How does MCMC work? For an answer, let's ask a politician. 
 
\end{itemize}



} 

\end{frame}




\begin{frame}{A politician stumbles upon the Metropolis algorithm}
\scriptsize{

\begin{itemize}
\item Suppose an elected politician lives on a long chain of islands.
\item He is constantly traveling from island to island, wanting to stay in the public eye. 
\item At the end of a day he has to decide whether to:

\begin{enumerate}
\scriptsize{
 \item stay on the current island
 \item move to the adjacent island to the west
 \item move to the adjacent island to east }
\end{enumerate}

\item His goal is to visit all the islands \textbf{proportionally} to their \textbf{relative population}.

\item But, he doesn't know the total population of all the islands.
\item He only knows the population of the current island where he is located.
\item He can also ask about the population of an adjacent island to which he plans to move.

\end{itemize}


} 
\end{frame}


\begin{frame}{The Metropolis algorithm}
\scriptsize{

\begin{itemize}
\item The politician has a simple heuristic for travelling accross the islands called the \textbf{Metropolis} algorithm.

\item First, he flips a (fair) coin to decide whether to propose the adjacent island to the left or the adjacent island to the right.

\item If the proposed island has a larger population than
the current island ($P_{proposed}>P_{current}$), then he  goes to the proposed island.

\item If the proposed island has a smaller population than the current island ($P_{proposed}<P_{current}$), then he goes to the proposed island with probability $p_{move}=P_{proposed}/P_{current}$.


\item In the long run, the probability that the politician is on any one of the islands exactly matches the relative population of the island!

\end{itemize}


} 
\end{frame}


\begin{frame}{The Metropolis algorithm}
\scriptsize{

\begin{itemize}
\item Let's analyze the Metropolis algorithm in more detail.
\item Suppose there are 10 islands in total.
\item Each island is neighbored by two others, and the
entire archipelago forms a ring.
\item The islands are of different sizes, and so had different sized populations living on them.
\item The second island is twice as populous as the first,
the third three times as populous as the first.
\item And so on, up to the largest island, which is 10 times as populous as the smallest.

\end{itemize}


} 
\end{frame}


\begin{frame}{The Metropolis algorithm}

   \begin{figure}[h!]
	\centering
	\includegraphics[scale=0.5]{pics/islands.png}
	\end{figure} 

\end{frame}




\begin{frame}{The Metropolis algorithm}
\scriptsize{

\begin{itemize}
\item We are going to show an implementation of this algorithm in R.

\item But before that, we will combine combine the two possibilities: the proposed island having a 1) higher or 2) lower population than the current island, into a single expression:

\begin{equation}
p_{move}=\min(1,P_{proposed}/P_{current}). 
\end{equation}

\item So, if $P_{proposed}>P_{current}$, $P_{proposed}/P_{current}>1$ and $p_{move}=1$.

\item For example, $current=4$ and $proposed=5$, $5/4>1$ so we move to the proposed island. 

\item On the other hand, if $P_{proposed}<P_{current}$, $P_{proposed}/P_{current}<1$, and $p_{move}=P_{proposed}/P_{current}$.

\item For example, $current=4$ and $proposed=3$, $3/4<1$ so we move to the proposed island with probability $3/4$.

\end{itemize}


} 
\end{frame}



\begin{frame}[fragile]{The Metropolis algorithm}
\scriptsize{


\begin{verbatim}
num_days <- 1e5
positions <- rep(0,num_days)
current <- 10
for ( i in 1:num_days ) {
  # record current position
  positions[i] <- current
  # flip coin to generate proposal
  proposal <- current + sample( c(-1,1) , size=1 )
  # now make sure he loops around the archipelago
  if ( proposal < 1 ) proposal <- 10
  if ( proposal > 10 ) proposal <- 1
  # move?
  prob_move <- min(proposal/current,1)
  decision <- rbinom(1,1,prob_move)
  current <- ifelse( decision == 1 , proposal , current )
}

library(rethinking)
simplehist(positions,xlab="island",ylab="number of days")
\end{verbatim}



} 
\end{frame}


\begin{frame}{The Metropolis algorithm}

   \begin{figure}[h!]
	\centering
	\includegraphics[scale=0.92]{pics/mcmc_islands.pdf}
	\end{figure} 

\scriptsize{
	The time spent on each island is proportional to its population size.}
	
\end{frame}



\begin{frame}{The Metropolis algorithm}
\scriptsize{

\begin{itemize}
\item The first three lines of the method just define
the number of days to simulate, an empty history vector, and a starting island position (the biggest island, number 10).
\item Then the for loop steps through the days. 
\item Each day, it records the politician's current position.
\item Then it simulates a coin flip to nominate a proposal island. 
\item The only trick here lies in making sure that a proposal of ``11'' loops around to island 1 and a proposal of “0” loops around to island 10.
\item Finally, a random binary number is generated with a binomial distribution with probability of success (or moving)$=\min(1,P_{proposed}/P_{current})$
\item If this random number is 1 we move, otherwise we stay.

\end{itemize}


} 
\end{frame}




\begin{frame}{The Metropolis algorithm}
\scriptsize{

\begin{itemize}
\item In real applications, the goal is of course not to help a politian, but instead to draw samples from an unknown and usually complex posterior probability distribution.
\item The ``islands'' in our objective are parameter values $\theta$, and they need not be discrete, but can instead take on a continuous range of values as usual.
\item The ``population sizes'' in our objective are the posterior probabilities (or densities) at each parameter value: $f(\theta|d)$
\item The ``days'' in our objective are samples taken from the posterior distribution.

\item The Metropolis algorithm will eventually give us a collection of samples from the posterior. 

\item We can then use these samples just like all the samples we have already used in this course.

\end{itemize}


} 
\end{frame}



\begin{frame}{Why it works}
\scriptsize{

\begin{itemize}
\item Now, let's try to understand the mathematics behind why the algorithm works.

\item Consider two adjacent positions and the probabilities of moving from one to the other. 
\item We'll see that the relative transition probabilities, between adjacent positions, exactly match the relative values of the target distribution.

\item Extrapolate that result across all the positions, and you can see that, in the long run, each position will be visited proportionally to its target value.

\item Suppose we are at position $\theta$. 

\item The probability of moving to $\theta+ 1$, denoted
$P(\theta \rightarrow \theta + 1)$, is the probability of proposing that move times the probability of
accepting it if proposed, which is:
\begin{displaymath}
P(\theta \rightarrow \theta + 1) = 0.5 \times \min(P(\theta+ 1)/P(\theta),1) 
\end{displaymath}



\end{itemize}


} 
\end{frame}


\begin{frame}{Conclusions}
\scriptsize{

\begin{itemize}
\item Blabla
\end{itemize}


} 
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[allowframebreaks]\scriptsize
\frametitle{References}
\bibliography{bio}
\bibliographystyle{apalike}
%\bibliographystyle{flexbib}
\end{frame}  









%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
